{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkML0105ENSkillsNetwork3498-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning in Python**\n",
    "\n",
    "Estimated time needed: **30** minutes\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Implement TensorFlow using Keras API\n",
    " - Implement PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#TensorFlow-using-Keras-API-With-a-Binary-Classification-Dataset\">TensorFlow using Keras API With a Binary Classification Dataset</a></li>\n",
    "    <li><a href=\"#PyTorch-with-A-Regression-Dataset\"> PyTorch with A Regression Dataset</a></li>\n",
    "            \n",
    "<li><a href=\"#Exercises\">Exercises</a></li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*  `tensorflow`: main package of TensorFlow that provides tensor operations and other functionalities.\n",
    "*  `tensorflow.keras.models.Sequential`: a class that allows you to build a sequential model, where layers are added in a sequential manner.\n",
    "* `tensorflow.keras.layers.Dense`: is a class representing a fully connected (dense) layer in a neural network.\n",
    "* `torch`: is the main package of PyTorch that provides tensor operations and other functionalities.\n",
    "* `torch.nn`: provides classes and functions for defining and working with neural networks.\n",
    "* `torch.optim`: provides optimization algorithms for training neural networks.\n",
    "*  `sklearn.datasets.make_classification`: generates a random classification dataset with specified characteristics. \n",
    "* `sklearn.model_selection.train_test_split`: splits a dataset into training and testing subsets.\n",
    "* `sklearn.preprocessing.StandardScaler`: standardizes features by removing the mean and scaling to unit variance. Standardizing the features helps in cases where the input features have different scales or distributions, as it brings them to a comparable range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow using Keras API With a Binary Classification Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow incorporates Keras as its official high-level API.** This integration offers the benefits of both TensorFlow and Keras:\n",
    "\n",
    "TensorFlow provides a powerful deep learning framework with low-level operations and tools for building and training neural networks. However, it can be complex and require more code to work directly with TensorFlow.\n",
    "Keras is a user-friendly and intuitive high-level neural network library in Python. It simplifies model definition, layer configuration, and training settings, enabling faster prototyping.\n",
    "TensorFlow's integration with Keras allows users to leverage the simplicity and ease of Keras while benefiting from TensorFlow's flexibility and scalability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet provided below demonstrates a simple example of using the PyTorch framework to build, train, and make predictions with a neural network model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/datasets/samples_generator.py:191: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros(n_samples, dtype=np.int)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/datasets/samples_generator.py:32: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  random_state=rng).astype(dtype='>u4',\n",
      "2025-02-17 19:16:11.866723: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2025-02-17 19:16:11.941785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494060000 Hz\n",
      "2025-02-17 19:16:11.942533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a98f3c16d0 executing computations on platform Host. Devices:\n",
      "2025-02-17 19:16:11.942597: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2025-02-17 19:16:12.023325: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 336us/sample - loss: 0.7590 - acc: 0.4850\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.7119 - acc: 0.4863\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.6789 - acc: 0.5063\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.6550 - acc: 0.5412\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.6375 - acc: 0.6062\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.6241 - acc: 0.6812\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.6133 - acc: 0.7312\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 59us/sample - loss: 0.6042 - acc: 0.7650\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5961 - acc: 0.7887\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 69us/sample - loss: 0.5890 - acc: 0.8112\n",
      "200/200 [==============================] - 0s 148us/sample - loss: 0.5923 - acc: 0.7900\n",
      "Test Loss: 0.5923071503639221\n",
      "Test Accuracy: 0.79\n",
      "Predicted Probabilities:\n",
      "[0.441056]\n",
      "[0.6911463]\n",
      "[0.49075708]\n",
      "[0.5741224]\n",
      "[0.4535338]\n",
      "[0.62520456]\n",
      "[0.4119594]\n",
      "[0.4332469]\n",
      "[0.42759442]\n",
      "[0.49635902]\n",
      "\n",
      "Binary Predictions:\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Generate a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "# The model consists of two fully connected (Dense) layers.\n",
    "model = Sequential([ \n",
    "    Dense(10, activation='sigmoid', input_shape=(10,)), # The first layer has 10 units and uses the sigmoid activation function. The input shape (10,) specifies that each input sample has 10 features.\n",
    "    Dense(1, activation='sigmoid') # The second layer has 1 unit and also uses the sigmoid activation function.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy']) #'sgd'represents `Stochastic Gradient Descent`\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted Probabilities:\")\n",
    "for i in range(10):\n",
    "    print(predictions[i])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "binary_predictions = [1 if pred >= 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Print the binary predictions for the first 10 samples\n",
    "print(\"\\nBinary Predictions:\")\n",
    "for i in range(10):\n",
    "    print(binary_predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch with A Regression Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet provided below demonstrates a simple example of using the PyTorch framework to build, train, and make predictions with a neural network model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input data\n",
    "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8, 10], dtype=torch.float32)\n",
    "\n",
    "# Define the model architecture\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad() # The optimizer's gradients are reset to zero to avoid accumulating gradients from previous iterations.\n",
    "    outputs = model(x.unsqueeze(1)) # The input features are passed through the model to obtain the predicted outputs.\n",
    "    loss = criterion(outputs.squeeze(1), y) # The loss between the predicted outputs and the true target values is calculated.\n",
    "    loss.backward() # Backpropagation is performed by calling loss.backward() to compute the gradients of the loss with respect to the model's parameters.\n",
    "    optimizer.step() # The optimizer updates the model's parameters using optimizer.step(), adjusting the weights and biases based on the computed gradients.\n",
    "\n",
    "# Use the trained model to make predictions on a new set of input features [6, 7, 8, 9, 10]\n",
    "predictions = model(torch.tensor([6, 7, 8, 9, 10], dtype=torch.float32).unsqueeze(1)) \n",
    "print(predictions.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - TensorFlow using Keras API with a regression dataset\n",
    "Based on the given data below, complete the following tasks:\n",
    "\n",
    "1. Create a sequential model with a single dense layer\n",
    "2. Compile the model with the specified optimizer, loss function, and metrics: `optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error']`\n",
    "3. Modify the number of epochs to `20` during model training.\n",
    "4. Evaluate the model\n",
    "5. Use the trained model to make predictions on the test data (`test_data`) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "test_data = [6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 66.6038 - mean_squared_error: 66.6038\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 35.3446 - mean_squared_error: 35.3446\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 263us/sample - loss: 18.7675 - mean_squared_error: 18.7675\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 337us/sample - loss: 9.9765 - mean_squared_error: 9.9765\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 278us/sample - loss: 5.3145 - mean_squared_error: 5.3145\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 325us/sample - loss: 2.8420 - mean_squared_error: 2.8420\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 352us/sample - loss: 1.5307 - mean_squared_error: 1.5307\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.8351 - mean_squared_error: 0.8351\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 279us/sample - loss: 0.4661 - mean_squared_error: 0.4661\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 307us/sample - loss: 0.2703 - mean_squared_error: 0.2703\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 263us/sample - loss: 0.1663 - mean_squared_error: 0.1663\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 251us/sample - loss: 0.1110 - mean_squared_error: 0.1110\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 304us/sample - loss: 0.0815 - mean_squared_error: 0.0815\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 346us/sample - loss: 0.0658 - mean_squared_error: 0.0658\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 259us/sample - loss: 0.0573 - mean_squared_error: 0.0573\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0526 - mean_squared_error: 0.0526\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 301us/sample - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 278us/sample - loss: 0.0485 - mean_squared_error: 0.0485\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0475 - mean_squared_error: 0.0475\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 252us/sample - loss: 0.0469 - mean_squared_error: 0.0469\n",
      "1/1 [==============================] - 0s 25ms/sample - loss: 0.0587 - mean_squared_error: 0.0587\n",
      "Test MSE: 0.05872733\n",
      "Predicted Probabilities:\n",
      "[11.691704]\n",
      "[13.554045]\n",
      "[15.416387]\n",
      "[17.278728]\n",
      "[19.14107]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "# The model consists of a single (Dense) layer.\n",
    "model = Sequential([ \n",
    "    Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error']) #'sgd'represents `Stochastic Gradient Descent`\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Print the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted Probabilities:\")\n",
    "for i in predictions:\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, epochs=20)\n",
    "\n",
    "# Evaluate the model and get the mean squared error\n",
    "_, mse = model.evaluate(x, y)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions = model.predict(test_data)\n",
    "print(predictions)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Pytorch with a binary classification dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the given data below, complete the following tasks:\n",
    "1. Use `BCELoss()` to be the loss function class. `BCELoss()` represents binary cross-entropy loss.\n",
    "2. Choose the `SGD` (Stochastic Gradient Descent) to be the optimizer.\n",
    "3. Train the model with `10` epochs.\n",
    "4. Use the trained model to make prediction on the test data (`test_data`) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "# Given data\n",
    "X = torch.randn(1000, 10)\n",
    "y = torch.randint(0, 2, (1000, 1)).float()\n",
    "test_data = torch.randn(200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad() # The optimizer's gradients are reset to zero to avoid accumulating gradients from previous iterations.\n",
    "    outputs = model(X.unsqueeze(1)) # The input features are passed through the model to obtain the predicted outputs.\n",
    "    loss = criterion(outputs.squeeze(1), y) # The loss between the predicted outputs and the true target values is calculated.\n",
    "    loss.backward() # Backpropagation is performed by calling loss.backward() to compute the gradients of the loss with respect to the model's parameters.\n",
    "    optimizer.step() # The optimizer updates the model's parameters using optimizer.step(), adjusting the weights and biases based on the computed gradients.\n",
    "\n",
    "# Use the trained model to make predictions on a new set of input features [6, 7, 8, 9, 10]\n",
    "predictions = model(test_data)\n",
    "    \n",
    "#print(predictions.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions = model(test_data)\n",
    "predictions = predictions.detach().numpy()\n",
    "\n",
    "print(predictions)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "[Vicky Kuo](https://author.skills.network/instructors/vicky_kuo?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkML0105ENSkillsNetwork3498-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-06-19|0.1|Vicky Kuo|Designd and Created the Lab||Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
